python -m torch.distributed.launch --master_port=8679 --nproc_per_node=1 \
examples/text-classification/run_glue.py \
--model_name_or_path microsoft/deberta-v3-base \
--task_name qnli \
--apply_lora --apply_adalora --lora_type svd \
--target_rank 1  --lora_r 2   \
--reg_orth_coef 0.1 \
--init_warmup 2000 --final_warmup 8000 --mask_interval 100 \
--beta1 0.85 --beta2 0.85 \
--lora_module query,key,value,intermediate,layer.output,attention.output \
--lora_alpha 32 \
--do_train --do_eval --max_seq_length 512 \
--per_device_train_batch_size 32 --learning_rate 5e-4  \
--num_train_epochs 5 --warmup_steps 500 \
--cls_dropout 0.1 --weight_decay 0.01 \
--evaluation_strategy steps --eval_steps 1000 \
--save_strategy steps --save_steps 16000 \
--logging_steps 300 \
--tb_writter_loginterval 300 \
--report_to tensorboard \
--seed 6 \
--root_output_dir ./output/debertav3-base/qnli \
--overwrite_output_dir
